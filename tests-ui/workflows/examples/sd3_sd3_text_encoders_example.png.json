{"prompt":"{\"3\": {\"inputs\": {\"seed\": 1023174949987877, \"steps\": 30, \"cfg\": 5.45, \"sampler_name\": \"euler\", \"scheduler\": \"sgm_uniform\", \"denoise\": 1.0, \"model\": [\"4\", 0], \"positive\": [\"16\", 0], \"negative\": [\"40\", 0], \"latent_image\": [\"53\", 0]}, \"class_type\": \"KSampler\"}, \"4\": {\"inputs\": {\"ckpt_name\": \"sd3_medium.safetensors\"}, \"class_type\": \"CheckpointLoaderSimple\"}, \"8\": {\"inputs\": {\"samples\": [\"3\", 0], \"vae\": [\"4\", 2]}, \"class_type\": \"VAEDecode\"}, \"9\": {\"inputs\": {\"filename_prefix\": \"ComfyUI\", \"images\": [\"8\", 0]}, \"class_type\": \"SaveImage\"}, \"16\": {\"inputs\": {\"text\": \"a bottle with a rainbow galaxy inside it on top of a wooden table on a snowy mountain top with the ocean and clouds in the background\", \"clip\": [\"43\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"40\": {\"inputs\": {\"text\": \"\", \"clip\": [\"43\", 0]}, \"class_type\": \"CLIPTextEncode\"}, \"41\": {\"inputs\": {\"clip_name\": \"t5xxl_fp16.safetensors\", \"type\": \"sd3\"}, \"class_type\": \"CLIPLoader\"}, \"42\": {\"inputs\": {\"clip_name1\": \"clip_l.safetensors\", \"clip_name2\": \"clip_g.safetensors\", \"type\": \"sd3\"}, \"class_type\": \"DualCLIPLoader\"}, \"43\": {\"inputs\": {\"clip_name1\": \"clip_l.safetensors\", \"clip_name2\": \"clip_g.safetensors\", \"clip_name3\": \"t5xxl_fp16.safetensors\"}, \"class_type\": \"TripleCLIPLoader\"}, \"53\": {\"inputs\": {\"width\": 1024, \"height\": 1024, \"batch_size\": 1}, \"class_type\": \"EmptySD3LatentImage\"}}","workflow":"{\"last_node_id\": 53, \"last_link_id\": 100, \"nodes\": [{\"id\": 8, \"type\": \"VAEDecode\", \"pos\": [1200, 96], \"size\": {\"0\": 210, \"1\": 46}, \"flags\": {}, \"order\": 10, \"mode\": 0, \"inputs\": [{\"name\": \"samples\", \"type\": \"LATENT\", \"link\": 7}, {\"name\": \"vae\", \"type\": \"VAE\", \"link\": 53, \"slot_index\": 1}], \"outputs\": [{\"name\": \"IMAGE\", \"type\": \"IMAGE\", \"links\": [51], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"VAEDecode\"}}, {\"id\": 9, \"type\": \"SaveImage\", \"pos\": [1440, 96], \"size\": {\"0\": 952.5112915039062, \"1\": 1007.9328002929688}, \"flags\": {}, \"order\": 11, \"mode\": 0, \"inputs\": [{\"name\": \"images\", \"type\": \"IMAGE\", \"link\": 51, \"slot_index\": 0}], \"properties\": {}, \"widgets_values\": [\"ComfyUI\"]}, {\"id\": 4, \"type\": \"CheckpointLoaderSimple\", \"pos\": [-96, 480], \"size\": {\"0\": 384.75592041015625, \"1\": 98}, \"flags\": {}, \"order\": 0, \"mode\": 0, \"outputs\": [{\"name\": \"MODEL\", \"type\": \"MODEL\", \"links\": [99], \"slot_index\": 0}, {\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"slot_index\": 1}, {\"name\": \"VAE\", \"type\": \"VAE\", \"links\": [53], \"slot_index\": 2}], \"properties\": {\"Node name for S&R\": \"CheckpointLoaderSimple\"}, \"widgets_values\": [\"sd3_medium.safetensors\"]}, {\"id\": 3, \"type\": \"KSampler\", \"pos\": [864, 96], \"size\": {\"0\": 315, \"1\": 262}, \"flags\": {}, \"order\": 9, \"mode\": 0, \"inputs\": [{\"name\": \"model\", \"type\": \"MODEL\", \"link\": 99, \"slot_index\": 0}, {\"name\": \"positive\", \"type\": \"CONDITIONING\", \"link\": 21}, {\"name\": \"negative\", \"type\": \"CONDITIONING\", \"link\": 80}, {\"name\": \"latent_image\", \"type\": \"LATENT\", \"link\": 100}], \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [7], \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"KSampler\"}, \"widgets_values\": [1023174949987877, \"randomize\", 30, 5.45, \"euler\", \"sgm_uniform\", 1]}, {\"id\": 40, \"type\": \"CLIPTextEncode\", \"pos\": [384, 336], \"size\": {\"0\": 432, \"1\": 192}, \"flags\": {}, \"order\": 8, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 97}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [80], \"shape\": 3, \"slot_index\": 0}], \"title\": \"Negative Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"\"], \"color\": \"#322\", \"bgcolor\": \"#533\"}, {\"id\": 53, \"type\": \"EmptySD3LatentImage\", \"pos\": [480, 576], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 1, \"mode\": 0, \"outputs\": [{\"name\": \"LATENT\", \"type\": \"LATENT\", \"links\": [100], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"EmptySD3LatentImage\"}, \"widgets_values\": [1024, 1024, 1]}, {\"id\": 50, \"type\": \"Note\", \"pos\": [-384, 144], \"size\": {\"0\": 223.34756469726562, \"1\": 254.37765502929688}, \"flags\": {}, \"order\": 2, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"SD3 supports different text encoder configurations, you can see how to load them here.\\n\\n\\nMake sure to put these files:\\nclip_g.safetensors\\nclip_l.safetensors\\nt5xxl_fp16.safetensors\\n\\n\\nIn the ComfyUI/models/clip directory\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}, {\"id\": 42, \"type\": \"DualCLIPLoader\", \"pos\": [-96, 144], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 3, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"DualCLIPLoader\"}, \"widgets_values\": [\"clip_l.safetensors\", \"clip_g.safetensors\", \"sd3\"]}, {\"id\": 43, \"type\": \"TripleCLIPLoader\", \"pos\": [-96, 288], \"size\": {\"0\": 315, \"1\": 106}, \"flags\": {}, \"order\": 4, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [96, 97], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"TripleCLIPLoader\"}, \"widgets_values\": [\"clip_l.safetensors\", \"clip_g.safetensors\", \"t5xxl_fp16.safetensors\"]}, {\"id\": 41, \"type\": \"CLIPLoader\", \"pos\": [-96, 0], \"size\": {\"0\": 315, \"1\": 82}, \"flags\": {}, \"order\": 5, \"mode\": 0, \"outputs\": [{\"name\": \"CLIP\", \"type\": \"CLIP\", \"links\": [], \"shape\": 3, \"slot_index\": 0}], \"properties\": {\"Node name for S&R\": \"CLIPLoader\"}, \"widgets_values\": [\"t5xxl_fp16.safetensors\", \"sd3\"]}, {\"id\": 16, \"type\": \"CLIPTextEncode\", \"pos\": [384, 96], \"size\": {\"0\": 432, \"1\": 192}, \"flags\": {}, \"order\": 7, \"mode\": 0, \"inputs\": [{\"name\": \"clip\", \"type\": \"CLIP\", \"link\": 96}], \"outputs\": [{\"name\": \"CONDITIONING\", \"type\": \"CONDITIONING\", \"links\": [21], \"slot_index\": 0}], \"title\": \"Positive Prompt\", \"properties\": {\"Node name for S&R\": \"CLIPTextEncode\"}, \"widgets_values\": [\"a bottle with a rainbow galaxy inside it on top of a wooden table on a snowy mountain top with the ocean and clouds in the background\"], \"color\": \"#232\", \"bgcolor\": \"#353\"}, {\"id\": 51, \"type\": \"Note\", \"pos\": [-96, 624], \"size\": {\"0\": 384, \"1\": 192}, \"flags\": {}, \"order\": 6, \"mode\": 0, \"properties\": {\"text\": \"\"}, \"widgets_values\": [\"sd3_medium.safetensors is the file that does not contain any CLIP/text encoder weights so you need to load them separately.\\n\\nThis file goes in the ComfyUI/models/checkpoints directory.\"], \"color\": \"#432\", \"bgcolor\": \"#653\"}], \"links\": [[7, 3, 0, 8, 0, \"LATENT\"], [21, 16, 0, 3, 1, \"CONDITIONING\"], [51, 8, 0, 9, 0, \"IMAGE\"], [53, 4, 2, 8, 1, \"VAE\"], [80, 40, 0, 3, 2, \"CONDITIONING\"], [96, 43, 0, 16, 0, \"CLIP\"], [97, 43, 0, 40, 0, \"CLIP\"], [99, 4, 0, 3, 0, \"MODEL\"], [100, 53, 0, 3, 3, \"LATENT\"]], \"groups\": [{\"title\": \"Different Text Encoder Configurations\", \"bounding\": [-144, -96, 480, 528], \"color\": \"#3f789e\", \"font_size\": 24}], \"config\": {}, \"extra\": {\"ds\": {\"scale\": 1.1, \"offset\": [411.2661670831156, 120.32129155939319]}}, \"version\": 0.4}"}