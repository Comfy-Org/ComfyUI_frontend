{
  "AddNoise": {
    "display_name": "AddNoise"
  },
  "AlignYourStepsScheduler": {
    "display_name": "AlignYourStepsScheduler"
  },
  "BasicGuider": {
    "display_name": "BasicGuider"
  },
  "BasicScheduler": {
    "display_name": "BasicScheduler"
  },
  "BetaSamplingScheduler": {
    "display_name": "BetaSamplingScheduler"
  },
  "Canny": {
    "display_name": "Canny"
  },
  "CFGGuider": {
    "display_name": "CFGGuider"
  },
  "CheckpointLoader": {
    "display_name": "Load Checkpoint With Config (DEPRECATED)"
  },
  "CheckpointLoaderSimple": {
    "display_name": "Load Checkpoint",
    "description": "Loads a diffusion model checkpoint, diffusion models are used to denoise latents.",
    "inputs": {
      "ckpt_name": {
        "tooltip": "The name of the checkpoint (model) to load."
      }
    },
    "outputs": {
      "0": {
        "tooltip": "The model used for denoising latents."
      },
      "1": {
        "tooltip": "The CLIP model used for encoding text prompts."
      },
      "2": {
        "tooltip": "The VAE model used for encoding and decoding images to and from latent space."
      }
    }
  },
  "CheckpointSave": {
    "display_name": "Save Checkpoint"
  },
  "CLIPAttentionMultiply": {
    "display_name": "CLIPAttentionMultiply"
  },
  "CLIPLoader": {
    "display_name": "Load CLIP",
    "description": "[Recipes]\n\nstable_diffusion: clip-l\nstable_cascade: clip-g\nsd3: t5 / clip-g / clip-l\nstable_audio: t5\nmochi: t5"
  },
  "CLIPMergeAdd": {
    "display_name": "CLIPMergeAdd"
  },
  "CLIPMergeSimple": {
    "display_name": "CLIPMergeSimple"
  },
  "CLIPMergeSubtract": {
    "display_name": "CLIPMergeSubtract"
  },
  "CLIPSave": {
    "display_name": "CLIPSave"
  },
  "CLIPSetLastLayer": {
    "display_name": "CLIP Set Last Layer"
  },
  "CLIPTextEncode": {
    "display_name": "CLIP Text Encode (Prompt)",
    "description": "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.",
    "inputs": {
      "text": {
        "tooltip": "The text to be encoded."
      },
      "clip": {
        "tooltip": "The CLIP model used for encoding the text."
      }
    },
    "outputs": {
      "0": {
        "tooltip": "A conditioning containing the embedded text used to guide the diffusion model."
      }
    }
  },
  "CLIPTextEncodeControlnet": {
    "display_name": "CLIPTextEncodeControlnet"
  },
  "CLIPTextEncodeFlux": {
    "display_name": "CLIPTextEncodeFlux"
  },
  "CLIPTextEncodeHunyuanDiT": {
    "display_name": "CLIPTextEncodeHunyuanDiT"
  },
  "CLIPTextEncodeSD3": {
    "display_name": "CLIPTextEncodeSD3"
  },
  "CLIPTextEncodeSDXL": {
    "display_name": "CLIPTextEncodeSDXL"
  },
  "CLIPTextEncodeSDXLRefiner": {
    "display_name": "CLIPTextEncodeSDXLRefiner"
  },
  "CLIPVisionEncode": {
    "display_name": "CLIP Vision Encode"
  },
  "CLIPVisionLoader": {
    "display_name": "Load CLIP Vision"
  },
  "CombineHooks2": {
    "display_name": "Combine Hooks [2]"
  },
  "CombineHooks4": {
    "display_name": "Combine Hooks [4]"
  },
  "CombineHooks8": {
    "display_name": "Combine Hooks [8]"
  },
  "ConditioningAverage": {
    "display_name": "ConditioningAverage"
  },
  "ConditioningCombine": {
    "display_name": "Conditioning (Combine)"
  },
  "ConditioningConcat": {
    "display_name": "Conditioning (Concat)"
  },
  "ConditioningSetArea": {
    "display_name": "Conditioning (Set Area)"
  },
  "ConditioningSetAreaPercentage": {
    "display_name": "Conditioning (Set Area with Percentage)"
  },
  "ConditioningSetAreaStrength": {
    "display_name": "ConditioningSetAreaStrength"
  },
  "ConditioningSetDefaultCombine": {
    "display_name": "Cond Set Default Combine"
  },
  "ConditioningSetMask": {
    "display_name": "Conditioning (Set Mask)"
  },
  "ConditioningSetProperties": {
    "display_name": "Cond Set Props"
  },
  "ConditioningSetPropertiesAndCombine": {
    "display_name": "Cond Set Props Combine"
  },
  "ConditioningSetTimestepRange": {
    "display_name": "ConditioningSetTimestepRange"
  },
  "ConditioningTimestepsRange": {
    "display_name": "Timesteps Range",
    "outputs": {
      "1": {
        "name": "BEFORE_RANGE"
      },
      "2": {
        "name": "AFTER_RANGE"
      }
    }
  },
  "ConditioningZeroOut": {
    "display_name": "ConditioningZeroOut"
  },
  "ControlNetApply": {
    "display_name": "Apply ControlNet (OLD)"
  },
  "ControlNetApplyAdvanced": {
    "display_name": "Apply ControlNet",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      }
    }
  },
  "ControlNetApplySD3": {
    "display_name": "Apply Controlnet with VAE",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      }
    }
  },
  "ControlNetInpaintingAliMamaApply": {
    "display_name": "ControlNetInpaintingAliMamaApply",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      }
    }
  },
  "ControlNetLoader": {
    "display_name": "Load ControlNet Model"
  },
  "CreateHookKeyframe": {
    "display_name": "Create Hook Keyframe",
    "outputs": {
      "0": {
        "name": "HOOK_KF"
      }
    }
  },
  "CreateHookKeyframesFromFloats": {
    "display_name": "Create Hook Keyframes From Floats",
    "outputs": {
      "0": {
        "name": "HOOK_KF"
      }
    }
  },
  "CreateHookKeyframesInterpolated": {
    "display_name": "Create Hook Keyframes Interp.",
    "outputs": {
      "0": {
        "name": "HOOK_KF"
      }
    }
  },
  "CreateHookLora": {
    "display_name": "Create Hook LoRA"
  },
  "CreateHookLoraModelOnly": {
    "display_name": "Create Hook LoRA (MO)"
  },
  "CreateHookModelAsLora": {
    "display_name": "Create Hook Model as LoRA"
  },
  "CreateHookModelAsLoraModelOnly": {
    "display_name": "Create Hook Model as LoRA (MO)"
  },
  "CropMask": {
    "display_name": "CropMask"
  },
  "DevToolsDeprecatedNode": {
    "display_name": "Deprecated Node",
    "description": "A deprecated node"
  },
  "DevToolsErrorRaiseNode": {
    "display_name": "Raise Error",
    "description": "Raise an error for development purposes"
  },
  "DevToolsErrorRaiseNodeWithMessage": {
    "display_name": "Raise Error with Message",
    "description": "Raise an error with message for development purposes"
  },
  "DevToolsExperimentalNode": {
    "display_name": "Experimental Node",
    "description": "A experimental node"
  },
  "DevToolsLongComboDropdown": {
    "display_name": "Long Combo Dropdown",
    "description": "A long combo dropdown"
  },
  "DevToolsNodeWithForceInput": {
    "display_name": "Node With Force Input",
    "description": "A node with a forced input"
  },
  "DevToolsNodeWithOnlyOptionalInput": {
    "display_name": "Node With Only Optional Input",
    "description": "A node with only optional input"
  },
  "DevToolsNodeWithOptionalInput": {
    "display_name": "Node With Optional Input",
    "description": "A node with an optional input"
  },
  "DevToolsNodeWithOutputList": {
    "display_name": "Node With Output List",
    "description": "A node with an output list",
    "outputs": {
      "0": {
        "name": "INTEGER OUTPUT"
      },
      "1": {
        "name": "INTEGER LIST OUTPUT"
      }
    }
  },
  "DevToolsNodeWithStringInput": {
    "display_name": "Node With String Input",
    "description": "A node with a string input"
  },
  "DevToolsNodeWithUnionInput": {
    "display_name": "Node With Union Input",
    "description": "A node with a union input"
  },
  "DiffControlNetLoader": {
    "display_name": "Load ControlNet Model (diff)"
  },
  "DifferentialDiffusion": {
    "display_name": "Differential Diffusion"
  },
  "DiffusersLoader": {
    "display_name": "DiffusersLoader"
  },
  "DisableNoise": {
    "display_name": "DisableNoise"
  },
  "DualCFGGuider": {
    "display_name": "DualCFGGuider"
  },
  "DualCLIPLoader": {
    "display_name": "DualCLIPLoader",
    "description": "[Recipes]\n\nsdxl: clip-l, clip-g\nsd3: clip-l, clip-g / clip-l, t5 / clip-g, t5\nflux: clip-l, t5"
  },
  "EmptyImage": {
    "display_name": "EmptyImage"
  },
  "EmptyLatentAudio": {
    "display_name": "EmptyLatentAudio",
    "inputs": {
      "batch_size": {
        "tooltip": "The number of latent images in the batch."
      }
    }
  },
  "EmptyLatentImage": {
    "display_name": "Empty Latent Image",
    "description": "Create a new batch of empty latent images to be denoised via sampling.",
    "inputs": {
      "width": {
        "tooltip": "The width of the latent images in pixels."
      },
      "height": {
        "tooltip": "The height of the latent images in pixels."
      },
      "batch_size": {
        "tooltip": "The number of latent images in the batch."
      }
    },
    "outputs": {
      "0": {
        "tooltip": "The empty latent image batch."
      }
    }
  },
  "EmptyLTXVLatentVideo": {
    "display_name": "EmptyLTXVLatentVideo"
  },
  "EmptyMochiLatentVideo": {
    "display_name": "EmptyMochiLatentVideo"
  },
  "EmptySD3LatentImage": {
    "display_name": "EmptySD3LatentImage"
  },
  "ExponentialScheduler": {
    "display_name": "ExponentialScheduler"
  },
  "FeatherMask": {
    "display_name": "FeatherMask"
  },
  "FlipSigmas": {
    "display_name": "FlipSigmas"
  },
  "FluxGuidance": {
    "display_name": "FluxGuidance"
  },
  "FreeU": {
    "display_name": "FreeU"
  },
  "FreeU_V2": {
    "display_name": "FreeU_V2"
  },
  "GITSScheduler": {
    "display_name": "GITSScheduler"
  },
  "GLIGENLoader": {
    "display_name": "GLIGENLoader"
  },
  "GLIGENTextBoxApply": {
    "display_name": "GLIGENTextBoxApply"
  },
  "GrowMask": {
    "display_name": "GrowMask"
  },
  "HypernetworkLoader": {
    "display_name": "HypernetworkLoader"
  },
  "HyperTile": {
    "display_name": "HyperTile"
  },
  "ImageBatch": {
    "display_name": "Batch Images"
  },
  "ImageBlend": {
    "display_name": "Image Blend"
  },
  "ImageBlur": {
    "display_name": "Image Blur"
  },
  "ImageColorToMask": {
    "display_name": "ImageColorToMask"
  },
  "ImageCompositeMasked": {
    "display_name": "ImageCompositeMasked"
  },
  "ImageCrop": {
    "display_name": "Image Crop"
  },
  "ImageFromBatch": {
    "display_name": "ImageFromBatch"
  },
  "ImageInvert": {
    "display_name": "Invert Image"
  },
  "ImageOnlyCheckpointLoader": {
    "display_name": "Image Only Checkpoint Loader (img2vid model)"
  },
  "ImageOnlyCheckpointSave": {
    "display_name": "ImageOnlyCheckpointSave"
  },
  "ImagePadForOutpaint": {
    "display_name": "Pad Image for Outpainting"
  },
  "ImageQuantize": {
    "display_name": "Image Quantize"
  },
  "ImageScale": {
    "display_name": "Upscale Image"
  },
  "ImageScaleBy": {
    "display_name": "Upscale Image By"
  },
  "ImageScaleToTotalPixels": {
    "display_name": "Scale Image to Total Pixels"
  },
  "ImageSharpen": {
    "display_name": "Image Sharpen"
  },
  "ImageToMask": {
    "display_name": "Convert Image to Mask"
  },
  "ImageUpscaleWithModel": {
    "display_name": "Upscale Image (using Model)"
  },
  "InpaintModelConditioning": {
    "display_name": "InpaintModelConditioning",
    "inputs": {
      "noise_mask": {
        "tooltip": "Add a noise mask to the latent so sampling will only happen within the mask. Might improve results or completely break things depending on the model."
      }
    },
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      },
      "2": {
        "name": "latent"
      }
    }
  },
  "InstructPixToPixConditioning": {
    "display_name": "InstructPixToPixConditioning",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      },
      "2": {
        "name": "latent"
      }
    }
  },
  "InvertMask": {
    "display_name": "InvertMask"
  },
  "JoinImageWithAlpha": {
    "display_name": "Join Image with Alpha"
  },
  "KarrasScheduler": {
    "display_name": "KarrasScheduler"
  },
  "KSampler": {
    "display_name": "KSampler",
    "description": "Uses the provided model, positive and negative conditioning to denoise the latent image.",
    "inputs": {
      "model": {
        "tooltip": "The model used for denoising the input latent."
      },
      "seed": {
        "tooltip": "The random seed used for creating the noise."
      },
      "steps": {
        "tooltip": "The number of steps used in the denoising process."
      },
      "cfg": {
        "tooltip": "The Classifier-Free Guidance scale balances creativity and adherence to the prompt. Higher values result in images more closely matching the prompt however too high values will negatively impact quality."
      },
      "sampler_name": {
        "tooltip": "The algorithm used when sampling, this can affect the quality, speed, and style of the generated output."
      },
      "scheduler": {
        "tooltip": "The scheduler controls how noise is gradually removed to form the image."
      },
      "positive": {
        "tooltip": "The conditioning describing the attributes you want to include in the image."
      },
      "negative": {
        "tooltip": "The conditioning describing the attributes you want to exclude from the image."
      },
      "latent_image": {
        "tooltip": "The latent image to denoise."
      },
      "denoise": {
        "tooltip": "The amount of denoising applied, lower values will maintain the structure of the initial image allowing for image to image sampling."
      }
    },
    "outputs": {
      "0": {
        "tooltip": "The denoised latent."
      }
    }
  },
  "KSamplerAdvanced": {
    "display_name": "KSampler (Advanced)"
  },
  "KSamplerSelect": {
    "display_name": "KSamplerSelect"
  },
  "LaplaceScheduler": {
    "display_name": "LaplaceScheduler"
  },
  "LatentAdd": {
    "display_name": "LatentAdd"
  },
  "LatentApplyOperation": {
    "display_name": "LatentApplyOperation"
  },
  "LatentApplyOperationCFG": {
    "display_name": "LatentApplyOperationCFG"
  },
  "LatentBatch": {
    "display_name": "LatentBatch"
  },
  "LatentBatchSeedBehavior": {
    "display_name": "LatentBatchSeedBehavior"
  },
  "LatentBlend": {
    "display_name": "Latent Blend"
  },
  "LatentComposite": {
    "display_name": "Latent Composite"
  },
  "LatentCompositeMasked": {
    "display_name": "LatentCompositeMasked"
  },
  "LatentCrop": {
    "display_name": "Crop Latent"
  },
  "LatentFlip": {
    "display_name": "Flip Latent"
  },
  "LatentFromBatch": {
    "display_name": "Latent From Batch"
  },
  "LatentInterpolate": {
    "display_name": "LatentInterpolate"
  },
  "LatentMultiply": {
    "display_name": "LatentMultiply"
  },
  "LatentOperationSharpen": {
    "display_name": "LatentOperationSharpen"
  },
  "LatentOperationTonemapReinhard": {
    "display_name": "LatentOperationTonemapReinhard"
  },
  "LatentRotate": {
    "display_name": "Rotate Latent"
  },
  "LatentSubtract": {
    "display_name": "LatentSubtract"
  },
  "LatentUpscale": {
    "display_name": "Upscale Latent"
  },
  "LatentUpscaleBy": {
    "display_name": "Upscale Latent By"
  },
  "LoadAudio": {
    "display_name": "LoadAudio"
  },
  "LoadImage": {
    "display_name": "Load Image"
  },
  "LoadImageMask": {
    "display_name": "Load Image (as Mask)"
  },
  "LoadLatent": {
    "display_name": "LoadLatent"
  },
  "LoraLoader": {
    "display_name": "Load LoRA",
    "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.",
    "inputs": {
      "model": {
        "tooltip": "The diffusion model the LoRA will be applied to."
      },
      "clip": {
        "tooltip": "The CLIP model the LoRA will be applied to."
      },
      "lora_name": {
        "tooltip": "The name of the LoRA."
      },
      "strength_model": {
        "tooltip": "How strongly to modify the diffusion model. This value can be negative."
      },
      "strength_clip": {
        "tooltip": "How strongly to modify the CLIP model. This value can be negative."
      }
    },
    "outputs": {
      "0": {
        "tooltip": "The modified diffusion model."
      },
      "1": {
        "tooltip": "The modified CLIP model."
      }
    }
  },
  "LoraLoaderModelOnly": {
    "display_name": "LoraLoaderModelOnly",
    "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.",
    "outputs": {
      "0": {
        "tooltip": "The modified diffusion model."
      }
    }
  },
  "LoraSave": {
    "display_name": "Extract and Save Lora",
    "inputs": {
      "model_diff": {
        "tooltip": "The ModelSubtract output to be converted to a lora."
      },
      "text_encoder_diff": {
        "tooltip": "The CLIPSubtract output to be converted to a lora."
      }
    }
  },
  "LTXVConditioning": {
    "display_name": "LTXVConditioning",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      }
    }
  },
  "LTXVImgToVideo": {
    "display_name": "LTXVImgToVideo",
    "inputs": {
      "image_noise_scale": {
        "tooltip": "Amount of noise to apply on conditioning image latent."
      }
    },
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      },
      "2": {
        "name": "latent"
      }
    }
  },
  "LTXVScheduler": {
    "display_name": "LTXVScheduler",
    "inputs": {
      "stretch": {
        "tooltip": "Stretch the sigmas to be in the range [terminal, 1]."
      },
      "terminal": {
        "tooltip": "The terminal value of the sigmas after stretching."
      }
    }
  },
  "MaskComposite": {
    "display_name": "MaskComposite"
  },
  "MaskToImage": {
    "display_name": "Convert Mask to Image"
  },
  "ModelMergeAdd": {
    "display_name": "ModelMergeAdd"
  },
  "ModelMergeAuraflow": {
    "display_name": "ModelMergeAuraflow"
  },
  "ModelMergeBlocks": {
    "display_name": "ModelMergeBlocks"
  },
  "ModelMergeFlux1": {
    "display_name": "ModelMergeFlux1"
  },
  "ModelMergeLTXV": {
    "display_name": "ModelMergeLTXV"
  },
  "ModelMergeMochiPreview": {
    "display_name": "ModelMergeMochiPreview"
  },
  "ModelMergeSD1": {
    "display_name": "ModelMergeSD1"
  },
  "ModelMergeSD2": {
    "display_name": "ModelMergeSD2"
  },
  "ModelMergeSD3_2B": {
    "display_name": "ModelMergeSD3_2B"
  },
  "ModelMergeSD35_Large": {
    "display_name": "ModelMergeSD35_Large"
  },
  "ModelMergeSDXL": {
    "display_name": "ModelMergeSDXL"
  },
  "ModelMergeSimple": {
    "display_name": "ModelMergeSimple"
  },
  "ModelMergeSubtract": {
    "display_name": "ModelMergeSubtract"
  },
  "ModelSamplingAuraFlow": {
    "display_name": "ModelSamplingAuraFlow"
  },
  "ModelSamplingContinuousEDM": {
    "display_name": "ModelSamplingContinuousEDM"
  },
  "ModelSamplingContinuousV": {
    "display_name": "ModelSamplingContinuousV"
  },
  "ModelSamplingDiscrete": {
    "display_name": "ModelSamplingDiscrete"
  },
  "ModelSamplingFlux": {
    "display_name": "ModelSamplingFlux"
  },
  "ModelSamplingLTXV": {
    "display_name": "ModelSamplingLTXV"
  },
  "ModelSamplingSD3": {
    "display_name": "ModelSamplingSD3"
  },
  "ModelSamplingStableCascade": {
    "display_name": "ModelSamplingStableCascade"
  },
  "ModelSave": {
    "display_name": "ModelSave"
  },
  "Morphology": {
    "display_name": "ImageMorphology"
  },
  "PairConditioningCombine": {
    "display_name": "Cond Pair Combine",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      }
    }
  },
  "PairConditioningSetDefaultCombine": {
    "display_name": "Cond Pair Set Default Combine",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      }
    }
  },
  "PairConditioningSetProperties": {
    "display_name": "Cond Pair Set Props",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      }
    }
  },
  "PairConditioningSetPropertiesAndCombine": {
    "display_name": "Cond Pair Set Props Combine",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      }
    }
  },
  "PatchModelAddDownscale": {
    "display_name": "PatchModelAddDownscale (Kohya Deep Shrink)"
  },
  "PerpNeg": {
    "display_name": "Perp-Neg (DEPRECATED by PerpNegGuider)"
  },
  "PerpNegGuider": {
    "display_name": "PerpNegGuider"
  },
  "PerturbedAttentionGuidance": {
    "display_name": "PerturbedAttentionGuidance"
  },
  "PhotoMakerEncode": {
    "display_name": "PhotoMakerEncode"
  },
  "PhotoMakerLoader": {
    "display_name": "PhotoMakerLoader"
  },
  "PolyexponentialScheduler": {
    "display_name": "PolyexponentialScheduler"
  },
  "PorterDuffImageComposite": {
    "display_name": "Porter-Duff Image Composite"
  },
  "PreviewAudio": {
    "display_name": "PreviewAudio"
  },
  "PreviewImage": {
    "display_name": "Preview Image",
    "description": "Saves the input images to your ComfyUI output directory."
  },
  "RandomNoise": {
    "display_name": "RandomNoise"
  },
  "RebatchImages": {
    "display_name": "Rebatch Images"
  },
  "RebatchLatents": {
    "display_name": "Rebatch Latents"
  },
  "RepeatImageBatch": {
    "display_name": "RepeatImageBatch"
  },
  "RepeatLatentBatch": {
    "display_name": "Repeat Latent Batch"
  },
  "RescaleCFG": {
    "display_name": "RescaleCFG"
  },
  "SamplerCustom": {
    "display_name": "SamplerCustom",
    "outputs": {
      "0": {
        "name": "output"
      },
      "1": {
        "name": "denoised_output"
      }
    }
  },
  "SamplerCustomAdvanced": {
    "display_name": "SamplerCustomAdvanced",
    "outputs": {
      "0": {
        "name": "output"
      },
      "1": {
        "name": "denoised_output"
      }
    }
  },
  "SamplerDPMAdaptative": {
    "display_name": "SamplerDPMAdaptative"
  },
  "SamplerDPMPP_2M_SDE": {
    "display_name": "SamplerDPMPP_2M_SDE"
  },
  "SamplerDPMPP_2S_Ancestral": {
    "display_name": "SamplerDPMPP_2S_Ancestral"
  },
  "SamplerDPMPP_3M_SDE": {
    "display_name": "SamplerDPMPP_3M_SDE"
  },
  "SamplerDPMPP_SDE": {
    "display_name": "SamplerDPMPP_SDE"
  },
  "SamplerEulerAncestral": {
    "display_name": "SamplerEulerAncestral"
  },
  "SamplerEulerAncestralCFGPP": {
    "display_name": "SamplerEulerAncestralCFG++"
  },
  "SamplerEulerCFGpp": {
    "display_name": "SamplerEulerCFG++"
  },
  "SamplerLCMUpscale": {
    "display_name": "SamplerLCMUpscale"
  },
  "SamplerLMS": {
    "display_name": "SamplerLMS"
  },
  "SaveAnimatedPNG": {
    "display_name": "SaveAnimatedPNG"
  },
  "SaveAnimatedWEBP": {
    "display_name": "SaveAnimatedWEBP"
  },
  "SaveAudio": {
    "display_name": "SaveAudio"
  },
  "SaveImage": {
    "display_name": "Save Image",
    "description": "Saves the input images to your ComfyUI output directory.",
    "inputs": {
      "images": {
        "tooltip": "The images to save."
      },
      "filename_prefix": {
        "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."
      }
    }
  },
  "SaveImageWebsocket": {
    "display_name": "SaveImageWebsocket"
  },
  "SaveLatent": {
    "display_name": "SaveLatent"
  },
  "SD_4XUpscale_Conditioning": {
    "display_name": "SD_4XUpscale_Conditioning",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      },
      "2": {
        "name": "latent"
      }
    }
  },
  "SDTurboScheduler": {
    "display_name": "SDTurboScheduler"
  },
  "SelfAttentionGuidance": {
    "display_name": "Self-Attention Guidance"
  },
  "SetClipHooks": {
    "display_name": "Set CLIP Hooks"
  },
  "SetHookKeyframes": {
    "display_name": "Set Hook Keyframes"
  },
  "SetLatentNoiseMask": {
    "display_name": "Set Latent Noise Mask"
  },
  "SetUnionControlNetType": {
    "display_name": "SetUnionControlNetType"
  },
  "SkipLayerGuidanceDiT": {
    "display_name": "SkipLayerGuidanceDiT",
    "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model."
  },
  "SkipLayerGuidanceSD3": {
    "display_name": "SkipLayerGuidanceSD3",
    "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model."
  },
  "SolidMask": {
    "display_name": "SolidMask"
  },
  "SplitImageWithAlpha": {
    "display_name": "Split Image with Alpha"
  },
  "SplitSigmas": {
    "display_name": "SplitSigmas",
    "outputs": {
      "0": {
        "name": "high_sigmas"
      },
      "1": {
        "name": "low_sigmas"
      }
    }
  },
  "SplitSigmasDenoise": {
    "display_name": "SplitSigmasDenoise",
    "outputs": {
      "0": {
        "name": "high_sigmas"
      },
      "1": {
        "name": "low_sigmas"
      }
    }
  },
  "StableCascade_EmptyLatentImage": {
    "display_name": "StableCascade_EmptyLatentImage",
    "outputs": {
      "0": {
        "name": "stage_c"
      },
      "1": {
        "name": "stage_b"
      }
    }
  },
  "StableCascade_StageB_Conditioning": {
    "display_name": "StableCascade_StageB_Conditioning"
  },
  "StableCascade_StageC_VAEEncode": {
    "display_name": "StableCascade_StageC_VAEEncode",
    "outputs": {
      "0": {
        "name": "stage_c"
      },
      "1": {
        "name": "stage_b"
      }
    }
  },
  "StableCascade_SuperResolutionControlnet": {
    "display_name": "StableCascade_SuperResolutionControlnet",
    "outputs": {
      "0": {
        "name": "controlnet_input"
      },
      "1": {
        "name": "stage_c"
      },
      "2": {
        "name": "stage_b"
      }
    }
  },
  "StableZero123_Conditioning": {
    "display_name": "StableZero123_Conditioning",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      },
      "2": {
        "name": "latent"
      }
    }
  },
  "StableZero123_Conditioning_Batched": {
    "display_name": "StableZero123_Conditioning_Batched",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      },
      "2": {
        "name": "latent"
      }
    }
  },
  "StyleModelApply": {
    "display_name": "Apply Style Model"
  },
  "StyleModelLoader": {
    "display_name": "Load Style Model"
  },
  "SV3D_Conditioning": {
    "display_name": "SV3D_Conditioning",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      },
      "2": {
        "name": "latent"
      }
    }
  },
  "SVD_img2vid_Conditioning": {
    "display_name": "SVD_img2vid_Conditioning",
    "outputs": {
      "0": {
        "name": "positive"
      },
      "1": {
        "name": "negative"
      },
      "2": {
        "name": "latent"
      }
    }
  },
  "ThresholdMask": {
    "display_name": "ThresholdMask"
  },
  "TomePatchModel": {
    "display_name": "TomePatchModel"
  },
  "TorchCompileModel": {
    "display_name": "TorchCompileModel"
  },
  "TripleCLIPLoader": {
    "display_name": "TripleCLIPLoader",
    "description": "[Recipes]\n\nsd3: clip-l, clip-g, t5"
  },
  "unCLIPCheckpointLoader": {
    "display_name": "unCLIPCheckpointLoader"
  },
  "unCLIPConditioning": {
    "display_name": "unCLIPConditioning"
  },
  "UNetCrossAttentionMultiply": {
    "display_name": "UNetCrossAttentionMultiply"
  },
  "UNETLoader": {
    "display_name": "Load Diffusion Model"
  },
  "UNetSelfAttentionMultiply": {
    "display_name": "UNetSelfAttentionMultiply"
  },
  "UNetTemporalAttentionMultiply": {
    "display_name": "UNetTemporalAttentionMultiply"
  },
  "UpscaleModelLoader": {
    "display_name": "Load Upscale Model"
  },
  "VAEDecode": {
    "display_name": "VAE Decode",
    "description": "Decodes latent images back into pixel space images.",
    "inputs": {
      "samples": {
        "tooltip": "The latent to be decoded."
      },
      "vae": {
        "tooltip": "The VAE model used for decoding the latent."
      }
    },
    "outputs": {
      "0": {
        "tooltip": "The decoded image."
      }
    }
  },
  "VAEDecodeAudio": {
    "display_name": "VAEDecodeAudio"
  },
  "VAEDecodeTiled": {
    "display_name": "VAE Decode (Tiled)"
  },
  "VAEEncode": {
    "display_name": "VAE Encode"
  },
  "VAEEncodeAudio": {
    "display_name": "VAEEncodeAudio"
  },
  "VAEEncodeForInpaint": {
    "display_name": "VAE Encode (for Inpainting)"
  },
  "VAEEncodeTiled": {
    "display_name": "VAE Encode (Tiled)"
  },
  "VAELoader": {
    "display_name": "Load VAE"
  },
  "VAESave": {
    "display_name": "VAESave"
  },
  "VideoLinearCFGGuidance": {
    "display_name": "VideoLinearCFGGuidance"
  },
  "VideoTriangleCFGGuidance": {
    "display_name": "VideoTriangleCFGGuidance"
  },
  "VPScheduler": {
    "display_name": "VPScheduler"
  },
  "WebcamCapture": {
    "display_name": "Webcam Capture"
  }
}